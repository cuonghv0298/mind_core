{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff9e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(\n",
    "    input_dir: str,\n",
    "    output_langchain_document: bool = False,\n",
    "):\n",
    "    \"\"\"Load data from the given directory.\"\"\"\n",
    "    from pdf2image import convert_from_path\n",
    "    from llama_index.readers.file import ImageReader\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    # Incase there are multiple pdfs in the directory, convert them to images then store under folder images.\n",
    "    images_root = os.path.join(input_dir, \"images\")\n",
    "    os.makedirs(images_root, exist_ok=True)\n",
    "\n",
    "    pdf_paths = glob.glob(os.path.join(input_dir, \"*.pdf\"))\n",
    "    for pdf_path in pdf_paths:\n",
    "        file_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        print(f\"Processing {pdf_path}\")\n",
    "        images = convert_from_path(pdf_path=pdf_path)\n",
    "        for idx, img in enumerate(images):\n",
    "            img.resize((850, 1100))\n",
    "            img.save(os.path.join(images_root, f\"{file_name}_{idx}.png\"))\n",
    "\n",
    "    # Load all data.\n",
    "    # Configure the ImageReader to keep images as base64\n",
    "    image_reader = ImageReader(keep_image=True, parse_text=False)\n",
    "\n",
    "    # Define a custom file extractor for image files\n",
    "    file_extractor = {\n",
    "        \".jpg\": image_reader,\n",
    "        \".png\": image_reader,\n",
    "        \".jpeg\": image_reader,\n",
    "    }\n",
    "    # Create the MultiModal index\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_dir=input_dir, recursive=True, file_extractor=file_extractor\n",
    "    ).load_data()\n",
    "\n",
    "    if output_langchain_document:\n",
    "        documents = [doc.to_langchain_format() for doc in documents]\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68a9cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /datadrive/man.pham/data/pdfs/images_pdf.pdf\n"
     ]
    }
   ],
   "source": [
    "tenant_name = \"wdm_55647e3f100b46dd9c21ea0a67d20458\"\n",
    "documents = data_loading(input_dir=\"/datadrive/man.pham/data/pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ffd5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 3.17 seconds\n",
      "Throughput: 0.32 requests per second\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import httpx\n",
    "import time\n",
    "import json\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core import (\n",
    "    Document,\n",
    ")\n",
    "from tasks import ETL_pipeline\n",
    "from llama_index.core.schema import (\n",
    "    ImageNode,\n",
    "    TextNode,\n",
    ")\n",
    "\n",
    "\n",
    "class IngestionRequest(BaseModel):\n",
    "    documents: List[Document]\n",
    "    collection_name: str\n",
    "    tenant: str\n",
    "\n",
    "\n",
    "url = \"http://10.10.193.73:5000/etl_task/\"\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = IngestionRequest.model_validate(\n",
    "    {\n",
    "        \"documents\": documents,\n",
    "        \"collection_name\": \"LlamaIndex_da9b7bb158e64c93bea491df09894psd\",\n",
    "        \"tenant\": tenant_name,\n",
    "    }\n",
    ").model_dump_json()\n",
    "\n",
    "\n",
    "def send_request(_):\n",
    "    try:\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=data)\n",
    "        return response.status_code\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "n_time = 1\n",
    "start_time = time.time()\n",
    "with Pool(processes=10) as pool:  # you can adjust the number of processes\n",
    "    results = pool.map(send_request, range(n_time))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "throughput = n_time / total_time  # requests per second\n",
    "\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")\n",
    "print(f\"Throughput: {throughput:.2f} requests per second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604a6e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '/datadrive/man.pham/data/pdfs/images/images_pdf_0.png',\n",
       " 'file_name': 'images_pdf_0.png',\n",
       " 'file_type': 'image/png',\n",
       " 'file_size': 933446,\n",
       " 'creation_date': '2025-04-21',\n",
       " 'last_modified_date': '2025-04-21'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad/miniconda3/envs/deploy_mind/lib/python3.9/site-packages/weaviate/warnings.py:314: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "# import weaviate\n",
    "# import os\n",
    "\n",
    "# client = weaviate.connect_to_custom(\n",
    "#     http_host=os.environ.get(\n",
    "#         \"WEAVIATE_HOST\"\n",
    "#     ),  # \"10.100.224.34\",  # URL only, no http prefix\n",
    "#     http_port=os.environ.get(\"WEAVIATE_HOST_PORT\"),  # \"8080\",\n",
    "#     http_secure=False,  # Set to True if https\n",
    "#     grpc_host=os.environ.get(\"WEAVIATE_GPC_URL\"),  #  \"10.100.224.34\",\n",
    "#     grpc_port=os.environ.get(\n",
    "#         \"WEAVIATE_GPC_URL_PORT\"\n",
    "#     ),  # \"50051\",      # Default is 50051, WCD uses 443\n",
    "#     grpc_secure=False,  # Edit as needed\n",
    "#     skip_init_checks=True,\n",
    "# )\n",
    "# vector_store = WeaviateVectorStore(\n",
    "#     weaviate_client=client, index_name=\"LlamaIndex_da9b7bb158e64c93bea491df09894psd\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.delete_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2144a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploy_mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
